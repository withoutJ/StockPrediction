{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predicting_stocks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNEsjKoZ1jDa31w8xQhtbKX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/withoutJ/StockPrediction/blob/master/predicting_stocks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnkEthNbCkT7"
      },
      "source": [
        "#because of issues with pandas_datareader in colab you will have to upgrade pandas_datareader and numpy before scraping data from yahoo finance\n",
        "# !pip install --upgrade pandas_datareader\n",
        "# !pip install --upgrade numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR8ESWMNOUXQ"
      },
      "source": [
        "Uncomment the model you want to use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQPEH6tbDFC0"
      },
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import pandas_datareader as web\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import *\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkjJ7vK7DMZ7"
      },
      "source": [
        "seq_len = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX0I58TjDIp4"
      },
      "source": [
        "companies_idx = [ 'AAPL', 'MSFT', 'AMZN', 'GOOG', 'GOOGL', 'FB', 'TSLA', 'V', 'JPM', 'JNJ', 'WMT', 'NVDA', 'PYPL', 'MA', 'DIS', 'PG', 'UNH', 'HD', 'BAC', 'INTC', 'NFLX', 'CMCSA', 'ADBE', 'CRM', 'ABT', 'VZ', 'NKE', 'XOM', 'KO', 'T', 'AVGO', 'TMO', 'LLY', 'CSCO', 'PFE', 'MRK', 'PEP', 'ABBV', 'ORCL', 'CVX', 'DHR', 'ACN', 'QCOM', 'TXN', 'MDT', 'MCD', 'NEE', 'COST', 'TMUS', 'WFC', 'UNP', 'HON', 'UPS', 'MS', 'AMGN', 'PM', 'C', 'BMY', 'LIN', 'LOW', 'BA', 'SBUX', 'CHTR', 'INTU', 'NOW', 'SCHW', 'BLK', 'AMD', 'RTX', 'CAT', 'AMAT', 'GS', 'EL', 'IBM', 'AXP', 'GE', 'MMM', 'AMT', 'DE', 'MU', 'TGT', 'LMT', 'SYK', 'ISRG', 'CVS', 'BKNG', 'LRCX', 'FIS', 'SPGI', 'GILD', 'TJX', 'MO', 'ATVI', 'ZTS', 'PLD', 'MDLZ', 'GM', 'TFC', 'BDX']\n",
        "no_companies = len(companies_idx)\n",
        "no_companies_train = math.ceil(no_companies*0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8qFJavDDcgc"
      },
      "source": [
        "list_companies = []\n",
        "test = []\n",
        "x = np.array([[]])\n",
        "first_date = datetime.now()\n",
        "#time_test = []\n",
        "#time_train = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umpJmlHBDOMa"
      },
      "source": [
        "i = 1\n",
        "for idx in companies_idx:\n",
        "  stock_df = web.DataReader(idx, data_source='yahoo', start='1980-01-01', end='2021-05-20')\n",
        "  stock = stock_df['Close']\n",
        "  first_date = min(first_date, stock.index[0])\n",
        "  stock_np = np.array(stock)\n",
        "  stock_np = np.reshape(stock_np, (len(stock_np), 1))\n",
        "  if i<=7:\n",
        "    test.append(stock_np)\n",
        "    #time_test.append(stock.index)\n",
        "  else:\n",
        "    list_companies.append(stock_np)\n",
        "    #time_train.append(stock.index)\n",
        "  i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw-01Kz4aktv"
      },
      "source": [
        "# for i in range(no_companies):\n",
        "#   if i>=7:\n",
        "#     time_train[i-7]=time_train[i-7]-first_date\n",
        "#     time_train[i-7] = time_train[i-7].days\n",
        "#     time_train[i-7] = np.array(time_train[i-7])\n",
        "#   else:\n",
        "#     time_test[i] = time_test[i]-first_date\n",
        "#     time_test[i] = time_test[i].days\n",
        "#     time_test[i] = np.array(time_test[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpe7mzdpcEVB"
      },
      "source": [
        "# x = np.reshape(x, (len(x),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlGmj_2NIEBp"
      },
      "source": [
        "Xtrain = []\n",
        "Ytrain = []\n",
        "#Xtrain_time = []\n",
        "br = 0\n",
        "for stck, day in zip(list_companies,time_train):\n",
        "  for i in range(seq_len,len(stck)):\n",
        "    #Xtrain_time.append(day[i-seq_len:i])\n",
        "    Xtrain.append((stck[i-seq_len:i]-stck[i-1])/stck[i-1])\n",
        "    Ytrain.append((stck[i]-stck[i-1])/stck[i-1])\n",
        "  br+=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfzwVVLpLcz3"
      },
      "source": [
        "Xtrain_time = np.array(Xtrain_time)\n",
        "Xtrain_time = np.reshape(Xtrain_time, (Xtrain_time.shape[0], Xtrain_time.shape[1], 1))\n",
        "\n",
        "Xtrain = np.array(Xtrain)\n",
        "Ytrain = np.array(Ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV_iBY-OWNpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3fb391c-c2ac-4b0f-9b9e-cc13be09acf8"
      },
      "source": [
        "print(Xtrain.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(762466, 10, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbNw9u68LeQt"
      },
      "source": [
        "#CNN MODEL\n",
        "\n",
        "# model = models.Sequential()\n",
        "\n",
        "# model.add(layers.Conv1D(64, 3, activation='relu', input_shape=(Xtrain.shape[1], 1)))\n",
        "# model.add(layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "# model.add(layers.Flatten())\n",
        "\n",
        "\n",
        "# model.add(layers.Dense(32))\n",
        "# model.add(layers.Dense(1))\n",
        "\n",
        "# print(model.summary())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qROq80iEFadM"
      },
      "source": [
        "#LSTM MODEL \n",
        "\n",
        "# model = models.Sequential()\n",
        "\n",
        "# model.add(layers.LSTM(20, return_sequences=True, input_shape=(Xtrain.shape[1], 1)))\n",
        "# model.add(layers.LSTM(20))\n",
        "\n",
        "# model.add(layers.Dense(32))\n",
        "# model.add(layers.Dense(1))\n",
        "\n",
        "# print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGQN1V7BdswO"
      },
      "source": [
        "#CNN+LSTM MODEL\n",
        "\n",
        "# model = models.Sequential()\n",
        "\n",
        "# units = 20\n",
        "\n",
        "# model.add(layers.Conv1D(32, 3, activation='relu', input_shape=(Xtrain.shape[1],1)))\n",
        "# model.add(layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "\n",
        "# model.add(tf.keras.layers.Reshape((model.output_shape[1]*model.output_shape[2],1)))\n",
        "\n",
        "# print(model.output_shape)\n",
        "\n",
        "# model.add(layers.LSTM(units, return_sequences=False, input_shape= (model.output_shape[1], 1)))\n",
        "# #model.add(LSTM(units, return_sequences=True))\n",
        "\n",
        "\n",
        "# model.add(layers.Dense(32))\n",
        "# model.add(layers.Dense(1))\n",
        "\n",
        "# print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u__hW4ZLijp"
      },
      "source": [
        "# class Time2Vec(Layer):\n",
        "#     def __init__(self, vec_size):\n",
        "#         super(Time2Vec, self).__init__()\n",
        "#         self.vec_size = vec_size \n",
        "    \n",
        "#     def build(self, input_shape):\n",
        "#         self.w_linear = self.add_weight(\n",
        "#             shape=(1, 1),\n",
        "#             initializer='uniform',\n",
        "#             trainable=True\n",
        "#         )\n",
        "        \n",
        "#         self.b_linear = self.add_weight(\n",
        "#             shape=(1, 1),\n",
        "#             initializer='uniform',\n",
        "#             trainable=True\n",
        "#         )\n",
        "\n",
        "#         self.w_periodic = self.add_weight(\n",
        "#             shape=(1, self.vec_size),\n",
        "#             initializer='uniform',\n",
        "#             trainable=True\n",
        "#         )\n",
        "        \n",
        "#         self.b_periodic = self.add_weight(\n",
        "#             shape=(1, self.vec_size),\n",
        "#             initializer='uniform',\n",
        "#             trainable=True\n",
        "#         )\n",
        "        \n",
        "#         super(Time2Vec, self).build(input_shape)\n",
        "    \n",
        "#     def call(self, inputs, **kwargs):\n",
        "#         linear = self.w_linear * inputs + self.b_linear\n",
        "#         periodic = K.sin(K.dot(inputs, self.w_periodic) + self.b_periodic)\n",
        "#         return K.concatenate([linear, periodic], -1)\n",
        "    \n",
        "#     def compute_output_shape(self, input_shape):\n",
        "#         return (input_shape[0], input_shape[1], self.vec_size + 1)\n",
        "\n",
        "# def time2vec_lstm(dim, t2v_dim):\n",
        "#   term = Input(shape=(dim, 1))\n",
        "#   time = Input(shape=(dim, 1))\n",
        "#   xti = Time2Vec(t2v_dim)(time)\n",
        "#   xte1 = LSTM(10, return_sequences=True)(term) \n",
        "#   xte2 = LSTM(10)(xte1)\n",
        "#   x = Dense(1)(concatenate([Flatten()(xte2), Flatten()(xti)]))\n",
        "#   m = Model(inputs=[time, term],outputs=x)\n",
        "#   return m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yEPuAoxqwtS"
      },
      "source": [
        "# model = time2vec_lstm(seq_len, 16) #uncomment this line to make time incorporated model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtMOaq5ULo9N"
      },
      "source": [
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkaNAh9cq4aI"
      },
      "source": [
        "#LSTM+Time2Vec fit \n",
        "# history_data = model.fit(x = [Xtrain_time, Xtrain], y = Ytrain, batch_size=50, epochs=20, verbose=2, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdwkf5ofLqs5"
      },
      "source": [
        "history_data = model.fit(Xtrain, Ytrain, batch_size=50, epochs=5, verbose=2, validation_split=0.2) #comment this if you are using time2vec model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVDO2c74iCOn"
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.title('Gubitak kroz epohe')\n",
        "plt.plot(history_data.history['loss'])\n",
        "plt.plot(history_data.history['val_loss'])\n",
        "plt.ylabel('Gubitak')\n",
        "plt.xlabel('Epohe')\n",
        "plt.legend(['trening gubitak' , 'validacioni gubitak'], loc = 'upper right')\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKzAQDiWoHIl"
      },
      "source": [
        "rmse = []\n",
        "rmse_y = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyUwPEhxLtdk"
      },
      "source": [
        "for stck, day in zip(test,time_test):\n",
        "  Xtest = []\n",
        "  Ytest = []\n",
        "  #Xtest_time = []\n",
        "  predictions_y = []\n",
        "  for i in range(seq_len, len(stck)):\n",
        "    Xtest.append((stck[i-seq_len:i]-stck[i-1])/stck[i-1])\n",
        "    predictions_y.append(0)\n",
        "    Ytest.append((stck[i]-stck[i-1])/stck[i-1])\n",
        "    #Xtest_time.append(day[i-seq_len:i])\n",
        "  Xtest = np.array(Xtest)\n",
        "  Ytest = np.array(Ytest)\n",
        "  #Xtest_time = np.array(Xtest_time)\n",
        "  #Xtest_time = np.reshape(Xtest_time, (Xtest_time.shape[0],Xtest_time.shape[1], 1))\n",
        "\n",
        "\n",
        "  predictions_y = np.array(predictions_y)\n",
        "  predictions = model.predict(Xtest)\n",
        "  #predictions = model.predict([Xtest_time,Xtest])\n",
        "\n",
        "  for i in range(len(predictions)):\n",
        "     predictions[i] = predictions[i]*stck[i-1+seq_len]+stck[i-1+seq_len]\n",
        "  \n",
        "  rmse.append(np.sqrt(np.mean(((predictions-Ytest)**2))))\n",
        "  rmse_y.append(np.sqrt(np.mean(((predictions_y-Ytest)**2))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAgHyF5LNFBs"
      },
      "source": [
        "print(rmse)\n",
        "print(rmse_y)"
      ],
      "execution_count": 2,
      "outputs": []
    }
  ]
}